{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqciXD15nxBFhfOugdJSFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tumblingdice512/Research/blob/master/model3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSlxLJdl4FBf"
      },
      "source": [
        "モデル3 シンプルなnumpyによる実装(tanhの使用)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO3bv7GY4UXb"
      },
      "source": [
        "モデルについて\n",
        "\n",
        "幅N、深さL+1(l=0,1,･･･,L)のネットワーク\n",
        "\n",
        "各パーセプトロンはM成分を持つスピンで各成分は+1か-1を取る\n",
        "\n",
        "第l層と第l+1層の各パーセプトロンの同一成分は全て結合→重みJ\n",
        "\n",
        "各層の重みJはΣJ^2 = Nと正規化されている\n",
        "\n",
        "第l層のスピンの値に重みをかけた値に対して符号関数をかませたものが第l+1層の値(0に対して+1か-1にする)\n",
        "\n",
        "ただし学習の際には、reluを使っている\n",
        "第l+1層の学習用の出力 = relu(第l層の出力)\n",
        "第l+1層のスピンの値 = sign(第l層の出力)\n",
        "\n",
        "初期条件としては、入力層と出力層のスピンの値を与える\n",
        "\n",
        "入力層のスピンの値と、初期の重みの条件から、出力層を予想して、損失関数(平均2乗誤差)を小さくするために重みを更新する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CerkwVNNK_K"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNMuCop_OHLz"
      },
      "source": [
        "N = 10\n",
        "L = 5"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF1PVsgFZsR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421c539a-9537-4cb4-df67-096a26648575"
      },
      "source": [
        "a = [1, -1]\n",
        "b = random.choice(a)\n",
        "\n",
        "print(b)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Lnd1zeOHZb"
      },
      "source": [
        "#S0 = np.array([random.choice([1,-1]) for i in range(N)])\n",
        "#SL = np.array([random.choice([1,-1]) for i in range(N)])\n",
        "\n",
        "#print(S0)\n",
        "#print(\"S0の要素数は\",len(S0))\n",
        "\n",
        "#print(SL)\n",
        "#print(\"SLの要素数は\",len(SL))\n",
        "\n",
        "#初期条件として与えるスピンを生成\n",
        "#各パーセプトロンのスピンの成分数を増やすときは、SOとSLを行列の形式にすればよい。"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oikA6IiSZrxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559e660e-5d5c-4fc1-81bd-459b9812a0cb"
      },
      "source": [
        "S0 = np.array([[random.choice([1,-1]) for i in range(N)],[random.choice([1,-1]) for i in range(N)],\n",
        "               [random.choice([1,-1]) for i in range(N)],[random.choice([1,-1]) for i in range(N)],\n",
        "               [random.choice([1,-1]) for i in range(N)],[random.choice([1,-1]) for i in range(N)],\n",
        "               [random.choice([1,-1]) for i in range(N)]])\n",
        "\n",
        "SL = np.array([[random.choice([1,-1]) for i in range(N)],[random.choice([1,-1]) for i in range(N)],\n",
        "               [random.choice([1,-1]) for i in range(N)],[random.choice([1,-1]) for i in range(N)],\n",
        "               [random.choice([1,-1]) for i in range(N)],[random.choice([1,-1]) for i in range(N)],\n",
        "               [random.choice([1,-1]) for i in range(N)]])\n",
        "\n",
        "M = len(S0)\n",
        "\n",
        "print(S0) #同じ配列内は、スピンの第μ成分がN個並んでいる。各パーセプトロンに直すには、転置を取る必要あり\n",
        "print(M) #Mに相当\n",
        "\n",
        "print(SL)\n",
        "\n",
        "\n"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  1  1  1  1 -1 -1  1 -1  1]\n",
            " [-1 -1  1  1 -1 -1 -1  1  1 -1]\n",
            " [ 1  1 -1 -1 -1  1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  1  1 -1  1]\n",
            " [-1  1 -1  1 -1 -1  1 -1  1  1]\n",
            " [-1  1 -1  1 -1 -1 -1 -1 -1 -1]\n",
            " [-1 -1  1  1 -1 -1 -1  1 -1  1]]\n",
            "7\n",
            "[[ 1  1 -1 -1 -1 -1 -1  1  1  1]\n",
            " [ 1  1  1 -1  1  1  1 -1  1 -1]\n",
            " [-1 -1 -1  1  1  1  1  1  1  1]\n",
            " [-1 -1 -1 -1  1  1  1  1 -1 -1]\n",
            " [-1  1  1 -1 -1 -1 -1 -1  1 -1]\n",
            " [-1 -1  1  1  1  1 -1 -1 -1  1]\n",
            " [-1  1  1  1 -1  1 -1  1 -1  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq26d3RJ0eNu",
        "outputId": "adcd8ddd-ab9b-498e-9280-dd7ec2a72b69"
      },
      "source": [
        "def spin_overlap(x,y):\n",
        "  for i in range(N) :\n",
        "\n",
        "    spin_overlap = np.dot(x.T[i],y.T[i])\n",
        "    return np.abs(spin_overlap/(M*N))\n",
        "\n",
        "spin_overlap(S0,SL)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04285714285714286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCMTxxexNN-p"
      },
      "source": [
        "def MSE(t, y):\n",
        "    mse = np.mean(np.sum(np.square(t-y),axis =1),axis = 0)\n",
        "    return mse\n",
        "\n"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVIYtUb5fl-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f8247c-84b0-42cc-e5e3-bae942a3e634"
      },
      "source": [
        "A = np.array([[3,5,1],[4,12,1]])\n",
        "print(A**2)\n",
        "A_norm = (np.sum(np.square(A),axis=0))**(1/2)\n",
        "\n",
        "A_normalized = A / A_norm\n",
        "A_normalized_2 = A / A_norm * (N**(1/2))\n",
        "\n",
        "print(A_norm)\n",
        "\n",
        "print(A_normalized)\n",
        "print(A_normalized_2)\n"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  9  25   1]\n",
            " [ 16 144   1]]\n",
            "[ 5.         13.          1.41421356]\n",
            "[[0.6        0.38461538 0.70710678]\n",
            " [0.8        0.92307692 0.70710678]]\n",
            "[[1.8973666  1.21626064 2.23606798]\n",
            " [2.52982213 2.91902553 2.23606798]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwKPA9rhgVAQ"
      },
      "source": [
        "def weight_norm(x):\n",
        "    x_norm = (np.sum(np.square(x),axis=0)**(1/2))\n",
        "    return x_norm"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka-cpwK6OHbw"
      },
      "source": [
        "class Network1():\n",
        "  #ネットワークを定義する\n",
        "  #構成[入力層, 第1層, 第2層, 第3層, 第4層, 第5層]\n",
        "  #全結合\n",
        "\n",
        "  def __init__(self):\n",
        "    #重みの定義\n",
        "    self.w1_1 = np.random.randn(N,N)\n",
        "    self.w2_1 = np.random.randn(N,N)\n",
        "    self.w3_1 = np.random.randn(N,N)\n",
        "    self.w4_1 = np.random.randn(N,N)\n",
        "    self.w5_1 = np.random.randn(N,N)\n",
        "\n",
        "    #重みの正規化\n",
        "    self.J1_1 = self.w1_1 / (weight_norm(self.w1_1)) * (N**(1/2))\n",
        "    self.J2_1 = self.w2_1 / (weight_norm(self.w2_1)) * (N**(1/2))\n",
        "    self.J3_1 = self.w3_1 / (weight_norm(self.w3_1)) * (N**(1/2))\n",
        "    self.J4_1 = self.w4_1 / (weight_norm(self.w4_1)) * (N**(1/2))\n",
        "    self.J5_1 = self.w5_1 / (weight_norm(self.w5_1)) * (N**(1/2))\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    self.layer0_1 = x\n",
        "    self.layer1_1 = np.tanh(np.dot(self.layer0_1, self.J1_1))\n",
        "    self.layer2_1 = np.tanh(np.dot(self.layer1_1, self.J2_1))\n",
        "    self.layer3_1 = np.tanh(np.dot(self.layer2_1, self.J3_1))\n",
        "    self.layer4_1 = np.tanh(np.dot(self.layer3_1, self.J4_1))\n",
        "    self.out_1 = np.sign((np.dot(self.layer4_1, self.J5_1)) + 10e-7)\n",
        "    return self.out_1\n",
        "    \n",
        "\n",
        "  def backward(self, t, y):\n",
        "    #誤差逆伝播\n",
        "    delta5_1 = -2*(t-y)\n",
        "    delta4_1 = np.dot(delta5_1,self.J5_1.T)\n",
        "    delta3_1 = np.dot(delta4_1 * (1 - np.tanh(delta4_1)**2),self.J4_1.T) \n",
        "    delta2_1 = np.dot(delta3_1 * (1 - np.tanh(delta3_1)**2),self.J3_1.T)\n",
        "    delta1_1 = np.dot(delta2_1 * (1 - np.tanh(delta2_1)**2),self.J2_1.T)\n",
        "\n",
        "    #重みの勾配\n",
        "    self.dedJ5_1 = np.dot(self.layer4_1.T, delta5_1) / delta5_1.shape[0]\n",
        "    self.dedJ4_1 = np.dot(self.layer3_1.T, delta4_1 * (1 - np.tanh(delta4_1)**2)) / delta4_1.shape[0]\n",
        "    self.dedJ3_1 = np.dot(self.layer2_1.T, delta3_1 * (1 - np.tanh(delta3_1)**2)) / delta3_1.shape[0]\n",
        "    self.dedJ2_1 = np.dot(self.layer1_1.T, delta2_1 * (1 - np.tanh(delta2_1)**2)) / delta2_1.shape[0]\n",
        "    self.dedJ1_1 = np.dot(self.layer0_1.T, delta1_1 * (1 - np.tanh(delta1_1)**2)) / delta1_1.shape[0]\n",
        "\n",
        "  def optimize_GradientDecent(self, lr):\n",
        "    #重みの更新    \n",
        "    self.J1_1 -= lr * self.dedJ1_1\n",
        "    self.J2_1 -= lr * self.dedJ2_1\n",
        "    self.J3_1 -= lr * self.dedJ3_1\n",
        "    self.J4_1 -= lr * self.dedJ4_1\n",
        "    self.J5_1 -= lr * self.dedJ5_1\n",
        "\n",
        "    #重みの正規化\n",
        "    self.J1_1 = self.J1_1 / (weight_norm(self.J1_1)) * (N**(1/2))\n",
        "    self.J2_1 = self.J2_1 / (weight_norm(self.J2_1)) * (N**(1/2))\n",
        "    self.J3_1 = self.J3_1 / (weight_norm(self.J3_1)) * (N**(1/2))\n",
        "    self.J4_1 = self.J4_1 / (weight_norm(self.J4_1)) * (N**(1/2))\n",
        "    self.J5_1 = self.J5_1 / (weight_norm(self.J5_1)) * (N**(1/2))\n",
        "\n"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEo2K02NyMvT"
      },
      "source": [
        "class Network2():\n",
        "  #ネットワークを定義する\n",
        "  #構成[入力層, 第1層, 第2層, 第3層, 第4層, 第5層]\n",
        "  #全結合\n",
        "\n",
        "  def __init__(self):\n",
        "    #重みの定義\n",
        "    self.w1_2 = np.random.randn(N,N)\n",
        "    self.w2_2 = np.random.randn(N,N)\n",
        "    self.w3_2 = np.random.randn(N,N)\n",
        "    self.w4_2 = np.random.randn(N,N)\n",
        "    self.w5_2 = np.random.randn(N,N)\n",
        "\n",
        "    #重みの正規化\n",
        "    self.J1_2 = self.w1_2 / (weight_norm(self.w1_2)) * (N**(1/2))\n",
        "    self.J2_2 = self.w2_2 / (weight_norm(self.w2_2)) * (N**(1/2))\n",
        "    self.J3_2 = self.w3_2 / (weight_norm(self.w3_2)) * (N**(1/2))\n",
        "    self.J4_2 = self.w4_2 / (weight_norm(self.w4_2)) * (N**(1/2))\n",
        "    self.J5_2 = self.w5_2 / (weight_norm(self.w5_2)) * (N**(1/2))\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    self.layer0_2 = x\n",
        "    self.layer1_2 = relu(np.dot(self.layer0_2, self.J1_2))\n",
        "    self.layer2_2 = relu(np.dot(self.layer1_2, self.J2_2))\n",
        "    self.layer3_2 = relu(np.dot(self.layer2_2, self.J3_2))\n",
        "    self.layer4_2 = relu(np.dot(self.layer3_2, self.J4_2))\n",
        "    self.out_2 = np.sign((np.dot(self.layer4_2, self.J5_2)) + 10e-7)\n",
        "    return self.out_2\n",
        "    \n",
        "\n",
        "  def backward(self, t, y):\n",
        "    #誤差逆伝播\n",
        "    delta5_2 = -2*(t-y)\n",
        "    delta4_2 = np.dot(delta5_2,self.J5_2.T)\n",
        "    delta3_2 = np.dot(delta4_2 * (1 - np.tanh(delta4_2)**2),self.J4_2.T) \n",
        "    delta2_2 = np.dot(delta3_2 * (1 - np.tanh(delta3_2)**2),self.J3_2.T)\n",
        "    delta1_2 = np.dot(delta2_2 * (1 - np.tanh(delta2_2)**2),self.J2_2.T)\n",
        "\n",
        "    #重みの勾配\n",
        "    self.dedJ5_2 = np.dot(self.layer4_2.T, delta5_2) / delta5_2.shape[0]\n",
        "    self.dedJ4_2 = np.dot(self.layer3_2.T, delta4_2 * (1 - np.tanh(delta4_2)**2)) / delta4_2.shape[0]\n",
        "    self.dedJ3_2 = np.dot(self.layer2_2.T, delta3_2 * (1 - np.tanh(delta3_2)**2)) / delta3_2.shape[0]\n",
        "    self.dedJ2_2 = np.dot(self.layer1_2.T, delta2_2 * (1 - np.tanh(delta2_2)**2)) / delta2_2.shape[0]\n",
        "    self.dedJ1_2 = np.dot(self.layer0_2.T, delta1_2 * (1 - np.tanh(delta1_2)**2)) / delta1_2.shape[0]\n",
        "\n",
        "  def optimize_GradientDecent(self, lr):\n",
        "    #重みの更新    \n",
        "    self.J1_2 -= lr * self.dedJ1_2\n",
        "    self.J2_2 -= lr * self.dedJ2_2\n",
        "    self.J3_2 -= lr * self.dedJ3_2\n",
        "    self.J4_2 -= lr * self.dedJ4_2\n",
        "    self.J5_2 -= lr * self.dedJ5_2\n",
        "\n",
        "    #重みの正規化\n",
        "    self.J1_2 = self.J1_2 / (weight_norm(self.J1_2)) * (N**(1/2))\n",
        "    self.J2_2 = self.J2_2 / (weight_norm(self.J2_2)) * (N**(1/2))\n",
        "    self.J3_2 = self.J3_2 / (weight_norm(self.J3_2)) * (N**(1/2))\n",
        "    self.J4_2 = self.J4_2 / (weight_norm(self.J4_2)) * (N**(1/2))\n",
        "    self.J5_2 = self.J5_2 / (weight_norm(self.J5_2)) * (N**(1/2))\n",
        "\n",
        "    "
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o10wudFlOHd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4bc3550-c70d-46a5-fa7f-dbe4cd106589"
      },
      "source": [
        "model_1 = Network1()\n",
        "model_2 = Network2()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.02\n",
        "# 学習エポック数\n",
        "n_epoch = 1000\n",
        "Loss_1 = []\n",
        "Loss_2 = []\n",
        "\n",
        "# n_epoch繰り返す\n",
        "for n in range(n_epoch):\n",
        "    y_1 = model_1.forward(S0)\n",
        "    y_2 = model_2.forward(S0)\n",
        "\n",
        "    loss_Network_1 = MSE(SL, y_1)\n",
        "    loss_Network_2 = MSE(SL, y_2)\n",
        "\n",
        "    model_1.backward(SL, y_1)\n",
        "    model_2.backward(SL, y_2)\n",
        "\n",
        "    model_1.optimize_GradientDecent(lr)\n",
        "    model_2.optimize_GradientDecent(lr)\n",
        "\n",
        "    #spin_overlap_0 = np.sum()\n",
        "\n",
        "    Loss_1.append(loss_Network_1)\n",
        "    Loss_2.append(loss_Network_2)\n",
        "\n",
        "    print('EPOCH ', n + 1, ' | TRAIN LOSS_1 ',loss_Network_1, '  TRAIN LOSS_2 ',loss_Network_2)\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH  1  | TRAIN LOSS_1  24.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  2  | TRAIN LOSS_1  23.428571428571427   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  3  | TRAIN LOSS_1  24.571428571428573   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  4  | TRAIN LOSS_1  22.857142857142858   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  5  | TRAIN LOSS_1  23.428571428571427   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  6  | TRAIN LOSS_1  23.428571428571427   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  7  | TRAIN LOSS_1  22.857142857142858   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  8  | TRAIN LOSS_1  23.428571428571427   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  9  | TRAIN LOSS_1  21.142857142857142   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  10  | TRAIN LOSS_1  22.285714285714285   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  11  | TRAIN LOSS_1  20.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  12  | TRAIN LOSS_1  21.142857142857142   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  13  | TRAIN LOSS_1  21.142857142857142   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  14  | TRAIN LOSS_1  19.428571428571427   TRAIN LOSS_2  12.0\n",
            "EPOCH  15  | TRAIN LOSS_1  20.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  16  | TRAIN LOSS_1  18.285714285714285   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  17  | TRAIN LOSS_1  19.428571428571427   TRAIN LOSS_2  8.0\n",
            "EPOCH  18  | TRAIN LOSS_1  15.428571428571429   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  19  | TRAIN LOSS_1  16.0   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  20  | TRAIN LOSS_1  14.285714285714286   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  21  | TRAIN LOSS_1  14.285714285714286   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  22  | TRAIN LOSS_1  13.142857142857142   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  23  | TRAIN LOSS_1  13.714285714285714   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  24  | TRAIN LOSS_1  12.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  25  | TRAIN LOSS_1  15.428571428571429   TRAIN LOSS_2  6.285714285714286\n",
            "EPOCH  26  | TRAIN LOSS_1  13.142857142857142   TRAIN LOSS_2  8.0\n",
            "EPOCH  27  | TRAIN LOSS_1  12.571428571428571   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  28  | TRAIN LOSS_1  13.142857142857142   TRAIN LOSS_2  8.0\n",
            "EPOCH  29  | TRAIN LOSS_1  12.571428571428571   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  30  | TRAIN LOSS_1  13.142857142857142   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  31  | TRAIN LOSS_1  13.714285714285714   TRAIN LOSS_2  8.0\n",
            "EPOCH  32  | TRAIN LOSS_1  14.285714285714286   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  33  | TRAIN LOSS_1  12.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  34  | TRAIN LOSS_1  13.142857142857142   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  35  | TRAIN LOSS_1  14.285714285714286   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  36  | TRAIN LOSS_1  13.142857142857142   TRAIN LOSS_2  5.714285714285714\n",
            "EPOCH  37  | TRAIN LOSS_1  10.285714285714286   TRAIN LOSS_2  3.4285714285714284\n",
            "EPOCH  38  | TRAIN LOSS_1  13.142857142857142   TRAIN LOSS_2  4.571428571428571\n",
            "EPOCH  39  | TRAIN LOSS_1  11.428571428571429   TRAIN LOSS_2  2.2857142857142856\n",
            "EPOCH  40  | TRAIN LOSS_1  12.0   TRAIN LOSS_2  2.2857142857142856\n",
            "EPOCH  41  | TRAIN LOSS_1  12.0   TRAIN LOSS_2  2.857142857142857\n",
            "EPOCH  42  | TRAIN LOSS_1  10.857142857142858   TRAIN LOSS_2  3.4285714285714284\n",
            "EPOCH  43  | TRAIN LOSS_1  11.428571428571429   TRAIN LOSS_2  4.0\n",
            "EPOCH  44  | TRAIN LOSS_1  9.714285714285714   TRAIN LOSS_2  2.857142857142857\n",
            "EPOCH  45  | TRAIN LOSS_1  9.142857142857142   TRAIN LOSS_2  4.571428571428571\n",
            "EPOCH  46  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  4.0\n",
            "EPOCH  47  | TRAIN LOSS_1  9.714285714285714   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  48  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  6.285714285714286\n",
            "EPOCH  49  | TRAIN LOSS_1  9.142857142857142   TRAIN LOSS_2  8.0\n",
            "EPOCH  50  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  51  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  52  | TRAIN LOSS_1  9.142857142857142   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  53  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  8.0\n",
            "EPOCH  54  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  6.285714285714286\n",
            "EPOCH  55  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  56  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  4.571428571428571\n",
            "EPOCH  57  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  58  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  59  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  4.571428571428571\n",
            "EPOCH  60  | TRAIN LOSS_1  6.285714285714286   TRAIN LOSS_2  2.857142857142857\n",
            "EPOCH  61  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  1.7142857142857142\n",
            "EPOCH  62  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  2.2857142857142856\n",
            "EPOCH  63  | TRAIN LOSS_1  9.714285714285714   TRAIN LOSS_2  3.4285714285714284\n",
            "EPOCH  64  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  4.571428571428571\n",
            "EPOCH  65  | TRAIN LOSS_1  9.142857142857142   TRAIN LOSS_2  5.714285714285714\n",
            "EPOCH  66  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  5.714285714285714\n",
            "EPOCH  67  | TRAIN LOSS_1  9.142857142857142   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  68  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  2.857142857142857\n",
            "EPOCH  69  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  4.0\n",
            "EPOCH  70  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  4.0\n",
            "EPOCH  71  | TRAIN LOSS_1  9.142857142857142   TRAIN LOSS_2  6.285714285714286\n",
            "EPOCH  72  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  73  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  3.4285714285714284\n",
            "EPOCH  74  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  3.4285714285714284\n",
            "EPOCH  75  | TRAIN LOSS_1  6.285714285714286   TRAIN LOSS_2  2.857142857142857\n",
            "EPOCH  76  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  1.7142857142857142\n",
            "EPOCH  77  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  4.0\n",
            "EPOCH  78  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  79  | TRAIN LOSS_1  6.285714285714286   TRAIN LOSS_2  5.714285714285714\n",
            "EPOCH  80  | TRAIN LOSS_1  6.285714285714286   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  81  | TRAIN LOSS_1  6.285714285714286   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  82  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  4.571428571428571\n",
            "EPOCH  83  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  5.714285714285714\n",
            "EPOCH  84  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  8.0\n",
            "EPOCH  85  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  86  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  87  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  4.571428571428571\n",
            "EPOCH  88  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  4.571428571428571\n",
            "EPOCH  89  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  6.285714285714286\n",
            "EPOCH  90  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  8.0\n",
            "EPOCH  91  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  92  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  93  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  8.0\n",
            "EPOCH  94  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  95  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  96  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  97  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  98  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  99  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  100  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  101  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  102  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  103  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  104  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  5.142857142857143\n",
            "EPOCH  105  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  106  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  107  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  108  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  8.0\n",
            "EPOCH  109  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  110  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  5.714285714285714\n",
            "EPOCH  111  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  6.285714285714286\n",
            "EPOCH  112  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  5.714285714285714\n",
            "EPOCH  113  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  114  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  115  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  116  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  117  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  118  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  8.0\n",
            "EPOCH  119  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  8.0\n",
            "EPOCH  120  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  121  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  122  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  123  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  124  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  125  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  8.0\n",
            "EPOCH  126  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  127  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  128  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  6.857142857142857\n",
            "EPOCH  129  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  8.0\n",
            "EPOCH  130  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  131  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  132  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  133  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  134  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  135  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  136  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  137  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  138  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  8.0\n",
            "EPOCH  139  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  140  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  141  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  142  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  143  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  8.0\n",
            "EPOCH  144  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  8.0\n",
            "EPOCH  145  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  146  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  147  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  148  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  149  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  150  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  151  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  152  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  153  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  154  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  8.0\n",
            "EPOCH  155  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  156  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  157  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  158  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  159  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  160  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  161  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  162  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  163  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  164  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  7.428571428571429\n",
            "EPOCH  165  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  166  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  167  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  168  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  169  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  170  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  171  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  8.0\n",
            "EPOCH  172  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  173  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  174  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  175  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  176  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  177  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  178  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  179  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  180  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  181  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  182  | TRAIN LOSS_1  11.428571428571429   TRAIN LOSS_2  12.0\n",
            "EPOCH  183  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  184  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  185  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  186  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  187  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  188  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  189  | TRAIN LOSS_1  9.714285714285714   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  190  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  191  | TRAIN LOSS_1  6.285714285714286   TRAIN LOSS_2  12.0\n",
            "EPOCH  192  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  193  | TRAIN LOSS_1  10.857142857142858   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  194  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  195  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  196  | TRAIN LOSS_1  9.142857142857142   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  197  | TRAIN LOSS_1  8.571428571428571   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  198  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  199  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  200  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  201  | TRAIN LOSS_1  6.285714285714286   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  202  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  203  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  204  | TRAIN LOSS_1  8.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  205  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  12.0\n",
            "EPOCH  206  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  207  | TRAIN LOSS_1  5.714285714285714   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  208  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  209  | TRAIN LOSS_1  5.142857142857143   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  210  | TRAIN LOSS_1  7.428571428571429   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  211  | TRAIN LOSS_1  6.857142857142857   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  212  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  213  | TRAIN LOSS_1  4.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  214  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  215  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  216  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  217  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  218  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  219  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  220  | TRAIN LOSS_1  4.571428571428571   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  221  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  222  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  223  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  224  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  225  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  226  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  227  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  228  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  229  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  230  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  231  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  232  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  233  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  234  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  235  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  236  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  237  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  238  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  239  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  240  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  241  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  242  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  243  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  244  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  245  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  246  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  12.0\n",
            "EPOCH  247  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  248  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  249  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  250  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  251  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  12.0\n",
            "EPOCH  252  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  253  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  254  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  255  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  256  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  12.0\n",
            "EPOCH  257  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  258  | TRAIN LOSS_1  2.857142857142857   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  259  | TRAIN LOSS_1  2.2857142857142856   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  260  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  261  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  16.0\n",
            "EPOCH  262  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  263  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  12.0\n",
            "EPOCH  264  | TRAIN LOSS_1  1.1428571428571428   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  265  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  266  | TRAIN LOSS_1  3.4285714285714284   TRAIN LOSS_2  12.0\n",
            "EPOCH  267  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  268  | TRAIN LOSS_1  1.7142857142857142   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  269  | TRAIN LOSS_1  0.5714285714285714   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  270  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  271  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  272  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  273  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  274  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  275  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  276  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  277  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  278  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  279  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  280  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  281  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  282  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  283  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  284  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  285  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  286  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  287  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  288  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  289  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  290  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  291  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  292  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  293  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  294  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  295  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  296  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  297  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  298  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  299  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  300  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  301  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  302  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  303  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  304  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  305  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  306  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  307  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  308  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  309  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  310  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  311  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  312  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  313  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  314  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  315  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  316  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  317  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  318  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  319  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  320  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  321  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  322  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  323  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  324  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  325  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  326  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  327  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  328  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  329  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  330  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  331  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  332  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  333  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  334  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  335  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  336  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  337  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  338  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  339  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  340  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  341  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  342  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  343  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  344  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  345  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  346  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  347  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  348  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  349  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  350  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  351  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  352  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  353  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  354  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  355  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  356  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  357  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  358  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  359  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  360  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  361  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  362  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  363  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  364  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  365  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  366  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  367  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  368  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  369  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  370  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  371  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  372  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  373  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  374  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  375  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  376  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  377  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  378  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  379  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  380  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  381  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  382  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  383  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  384  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  385  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  386  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  387  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  388  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  389  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  390  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  391  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  392  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  393  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  394  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  395  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  396  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  397  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  398  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  399  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  400  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  401  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  402  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  403  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  404  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  405  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  406  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  407  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  408  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  409  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  410  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  411  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  412  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  413  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  414  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  415  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  416  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  417  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  418  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  419  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  420  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  421  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  422  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  423  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  424  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  425  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  426  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  427  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  428  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  429  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  430  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  431  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  432  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  433  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  434  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  435  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  436  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  437  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  438  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  439  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  440  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  441  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  442  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  443  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  444  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  445  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  446  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  447  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  448  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  449  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  450  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  451  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  452  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  453  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  454  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  455  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  456  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  457  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  458  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  459  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  460  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  461  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  462  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  463  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  464  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  465  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  466  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  467  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  468  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  469  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  470  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  471  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  472  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  473  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  474  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  475  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  476  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  477  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  478  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  8.0\n",
            "EPOCH  479  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  480  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  481  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  482  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  483  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  484  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  485  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  486  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  487  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  488  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  489  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  490  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  491  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  492  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  493  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  494  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  495  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  496  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  497  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  498  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  499  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  500  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  501  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  502  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  503  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  504  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  505  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  506  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  507  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  508  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  509  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  510  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  511  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  512  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  513  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  514  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  515  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  516  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  517  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  518  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  519  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  520  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  521  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  522  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  523  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  524  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  525  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  526  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  527  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  528  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  529  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  530  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  531  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  532  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  533  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  534  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  535  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  536  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  537  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  538  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  539  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  540  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  541  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  542  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  543  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  544  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  545  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  546  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  547  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  548  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  549  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  550  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  551  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  552  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  553  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  554  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  555  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  556  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  557  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  558  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  559  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  560  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  561  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  562  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  563  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  564  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  565  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  566  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  567  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  568  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  569  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  570  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  571  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  572  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  573  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  574  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  18.285714285714285\n",
            "EPOCH  575  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  576  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  577  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  578  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  579  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  580  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  581  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  582  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  583  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  584  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  585  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  18.857142857142858\n",
            "EPOCH  586  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  587  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  588  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  589  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  590  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  591  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  592  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  593  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  594  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  595  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  596  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  597  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  598  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  599  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  600  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  601  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  602  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  603  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  604  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  605  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  606  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  607  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  608  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  609  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  610  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  611  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  612  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  613  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  614  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  615  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  616  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  18.285714285714285\n",
            "EPOCH  617  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  618  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  619  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  620  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  621  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  622  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  623  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  624  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  625  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  626  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  627  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  628  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  629  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  18.285714285714285\n",
            "EPOCH  630  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  631  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  632  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  633  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  634  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  635  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  636  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  637  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  638  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  639  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  640  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  641  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  642  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  643  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  644  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  645  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  646  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  647  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  648  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  649  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  650  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  651  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  652  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  653  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  654  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  655  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  656  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  657  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  658  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  659  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  660  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  661  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  662  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  663  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  664  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  665  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  666  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  667  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  668  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  669  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  670  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  671  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  672  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  673  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.714285714285715\n",
            "EPOCH  674  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  675  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  676  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  677  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  678  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  679  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  680  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  681  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  682  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  683  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  684  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  685  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  686  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  687  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  688  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  689  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  690  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  691  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  692  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  693  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  694  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  695  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  696  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  697  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  698  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  699  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  700  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  701  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  702  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  703  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  704  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  705  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  706  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  707  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  708  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  709  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  710  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  711  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  712  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  713  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  714  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  715  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  716  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  717  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  718  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  719  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  720  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  721  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  722  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  723  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  724  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  725  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  726  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  727  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  728  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  729  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  730  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  731  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  732  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  733  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  734  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  735  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  736  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  737  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  738  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  739  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  740  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  741  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  742  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  743  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  744  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  745  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  746  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  747  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  748  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  749  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  750  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  751  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  752  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  753  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  754  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  755  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  756  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  757  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  758  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  759  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  760  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  761  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  762  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  763  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  764  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  765  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  766  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  767  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  768  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  769  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  770  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  771  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  772  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  773  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  774  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  775  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  776  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  777  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  778  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  779  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  780  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  781  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  782  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  17.142857142857142\n",
            "EPOCH  783  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  784  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  785  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  786  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  787  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  788  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  789  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  790  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  791  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  792  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  793  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  794  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.571428571428573\n",
            "EPOCH  795  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  796  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  797  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  798  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  799  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  800  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  801  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  802  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  803  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  804  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  805  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  806  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  807  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  808  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  809  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  16.0\n",
            "EPOCH  810  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  811  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  812  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  813  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  814  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  815  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  816  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  817  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  818  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  819  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  820  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  821  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  822  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  823  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  824  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  825  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  826  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  827  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  828  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  829  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  830  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  831  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  832  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  833  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  834  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  835  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  836  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  837  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  838  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  839  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  840  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  841  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  842  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  15.428571428571429\n",
            "EPOCH  843  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  844  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  845  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  846  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  847  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  848  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  849  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  850  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  851  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  852  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  853  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  854  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  855  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  856  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  857  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  858  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  859  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  860  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  861  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  862  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  863  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  864  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  865  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  866  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  867  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  868  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  869  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  870  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  871  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  872  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.857142857142858\n",
            "EPOCH  873  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  874  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  875  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  876  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  877  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  878  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  879  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  880  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  881  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  882  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  883  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  884  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  885  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  886  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  887  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  888  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  889  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  890  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  891  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  892  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  893  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  894  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  895  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  896  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  897  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  898  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  899  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  900  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  901  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  902  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  903  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  904  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  905  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  906  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  907  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  908  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  909  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  910  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  911  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  912  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  913  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  914  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  915  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  916  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  917  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  918  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  919  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  920  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  921  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  8.571428571428571\n",
            "EPOCH  922  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  923  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  924  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  925  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  926  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  927  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  928  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  929  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  930  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  931  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  932  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  933  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  934  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  935  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  936  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  937  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  938  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  939  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  940  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  941  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  942  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  943  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  944  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  945  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  946  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  947  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  948  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  949  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  950  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  951  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  952  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  953  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  954  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  955  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  956  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  957  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  958  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  959  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  960  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  961  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  962  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  963  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  964  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  965  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  966  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  967  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  968  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  969  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  970  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  971  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  972  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  973  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  974  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.714285714285714\n",
            "EPOCH  975  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  976  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  977  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  978  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  979  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  980  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  981  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  982  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  983  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  9.142857142857142\n",
            "EPOCH  984  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  985  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  986  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  987  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  988  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n",
            "EPOCH  989  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  990  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  11.428571428571429\n",
            "EPOCH  991  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  992  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  14.285714285714286\n",
            "EPOCH  993  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  994  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  995  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.571428571428571\n",
            "EPOCH  996  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.285714285714286\n",
            "EPOCH  997  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.142857142857142\n",
            "EPOCH  998  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  12.0\n",
            "EPOCH  999  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  13.714285714285714\n",
            "EPOCH  1000  | TRAIN LOSS_1  0.0   TRAIN LOSS_2  10.857142857142858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ3d4OqIBLE9",
        "outputId": "e4f964b6-8cec-4610-e79e-15dcfc467830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "i = range(n_epoch)\n",
        "plt.plot(i, Loss_1)\n",
        "plt.plot(i, Loss_2)\n",
        "plt.show()"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBM9kt6qOHm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d431f8fe-d7c9-4ab4-f535-d34204158667"
      },
      "source": [
        "1print('1行目')\n",
        "print(y_1[0])\n",
        "print(SL[0])\n",
        "\n",
        "print('2行目')\n",
        "print(y_1[1])\n",
        "print(SL[1])\n",
        "\n",
        "print('3行目')\n",
        "print(y_1[2])\n",
        "print(SL[2])\n",
        "\n",
        "print('4行目')\n",
        "print(y_1[3])\n",
        "print(SL[3])\n",
        "\n",
        "print('5行目')\n",
        "print(y_1[4])\n",
        "print(SL[4])\n",
        "\n",
        "print('6行目')\n",
        "print(y_1[5])\n",
        "print(SL[5])"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1行目\n",
            "[ 1. -1.  1.  1.  1. -1. -1.  1. -1. -1.]\n",
            "[-1 -1 -1 -1  1 -1  1  1  1  1]\n",
            "2行目\n",
            "[-1. -1. -1.  1. -1. -1.  1.  1.  1. -1.]\n",
            "[-1 -1  1 -1 -1  1 -1  1 -1 -1]\n",
            "3行目\n",
            "[ 1. -1. -1.  1. -1. -1.  1.  1. -1. -1.]\n",
            "[-1  1  1  1  1 -1  1  1 -1 -1]\n",
            "4行目\n",
            "[ 1. -1.  1.  1.  1.  1.  1.  1.  1. -1.]\n",
            "[-1  1  1  1  1  1  1 -1  1 -1]\n",
            "5行目\n",
            "[ 1.  1.  1.  1.  1.  1. -1.  1. -1.  1.]\n",
            "[-1 -1 -1  1  1 -1  1 -1 -1 -1]\n",
            "6行目\n",
            "[-1.  1.  1. -1. -1.  1. -1. -1. -1.  1.]\n",
            "[ 1  1 -1  1 -1  1 -1 -1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRHcK1edOHrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5baaf2-c05e-4d1e-c2fa-da4e5624d15a"
      },
      "source": [
        "print('1行目')\n",
        "print(y_2[0])\n",
        "print(SL[0])\n",
        "\n",
        "print('2行目')\n",
        "print(y_2[1])\n",
        "print(SL[1])\n",
        "\n",
        "print('3行目')\n",
        "print(y_2[2])\n",
        "print(SL[2])\n",
        "\n",
        "print('4行目')\n",
        "print(y_2[3])\n",
        "print(SL[3])\n",
        "\n",
        "print('5行目')\n",
        "print(y_2[4])\n",
        "print(SL[4])\n",
        "\n",
        "print('6行目')\n",
        "print(y_2[5])\n",
        "print(SL[5])"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1行目\n",
            "[ 1.  1.  1. -1. -1.  1.  1. -1. -1.  1.]\n",
            "[-1 -1 -1 -1  1 -1  1  1  1  1]\n",
            "2行目\n",
            "[ 1.  1.  1. -1. -1. -1. -1.  1. -1.  1.]\n",
            "[-1 -1  1 -1 -1  1 -1  1 -1 -1]\n",
            "3行目\n",
            "[-1.  1.  1. -1. -1. -1.  1.  1. -1.  1.]\n",
            "[-1  1  1  1  1 -1  1  1 -1 -1]\n",
            "4行目\n",
            "[ 1.  1.  1. -1.  1.  1.  1. -1. -1.  1.]\n",
            "[-1  1  1  1  1  1  1 -1  1 -1]\n",
            "5行目\n",
            "[ 1.  1.  1. -1. -1. -1.  1.  1. -1.  1.]\n",
            "[-1 -1 -1  1  1 -1  1 -1 -1 -1]\n",
            "6行目\n",
            "[ 1.  1.  1. -1. -1.  1.  1.  1. -1.  1.]\n",
            "[ 1  1 -1  1 -1  1 -1 -1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCQ57LHkOHtT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}