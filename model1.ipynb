{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMdzBaAoVnStLG7i7q796N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tumblingdice512/Research/blob/master/model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CerkwVNNK_K"
      },
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEQ6156LOFYu"
      },
      "source": [
        "#モデルについて\n",
        "#幅N、深さL+1(l=0,1,･･･,L)のネットワーク\n",
        "#各パーセプトロンはM成分を持つスピンで各成分は+1か-1を取る\n",
        "#第l層と第l+1層の各パーセプトロンの同一成分は全て結合→重みJ\n",
        "#各層の重みJはΣJ**2 = Nと正規化されている\n",
        "#第l層のスピンの値に重みをかけた値に対して符号関数をかませたものが第l+1層の値(0に対しては+1か-1にする)\n",
        "#初期条件としては、入力層と出力層のスピンの値を与える\n",
        "#入力層のスピンの値と、初期の重みの条件から、出力層を予想して、\n",
        "#\n",
        "#\n",
        "#\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNMuCop_OHLz"
      },
      "source": [
        "N = 10\n",
        "L = 5"
      ],
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF1PVsgFZsR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8268fa55-4e86-41f4-e13f-a3b9d658c127"
      },
      "source": [
        "a = [1, -1]\n",
        "b = random.choice(a)\n",
        "\n",
        "print(b)"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Lnd1zeOHZb"
      },
      "source": [
        "#S0 = np.array([random.choice([1,-1]) for i in range(N)])\n",
        "#SL = np.array([random.choice([1,-1]) for i in range(N)])\n",
        "\n",
        "#print(S0)\n",
        "#print(\"S0の要素数は\",len(S0))\n",
        "\n",
        "#print(SL)\n",
        "#print(\"SLの要素数は\",len(SL))\n",
        "\n",
        "#初期条件として与えるスピンを生成\n",
        "#各パーセプトロンのスピンの成分数を増やすときは、SOとSLを行列の形式にすればよい。"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oikA6IiSZrxm"
      },
      "source": [
        "S0 = np.array([[random.choice([1,-1]) for i in range(N)],[random.choice([1,-1]) for i in range(N)]])\n",
        "SL = np.array([[random.choice([1,-1]) for i in range(N)],[random.choice([1,-1]) for i in range(N)]])\n",
        "\n",
        "#print(S0)\n",
        "\n",
        "#print(SL)\n",
        "\n",
        "#S0とSLの成分数が2の時"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCMTxxexNN-p"
      },
      "source": [
        "def MSE(t, y):\n",
        "    mse = np.mean(np.sum(np.square(t-y),axis =1),axis = 0)\n",
        "    return mse\n",
        "\n"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVIYtUb5fl-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08d1685-811f-4999-8d7f-45fe6f57a2d5"
      },
      "source": [
        "A = np.array([[3,5,1],[4,12,1]])\n",
        "print(A**2)\n",
        "A_norm = (np.sum(np.square(A),axis=0))**(1/2)\n",
        "\n",
        "A_normalized = A / A_norm\n",
        "A_normalized_2 = A / A_norm * (N**(1/2))\n",
        "\n",
        "print(A_norm)\n",
        "print(A_norm_2)\n",
        "\n",
        "print(A_normalized)\n",
        "print(A_normalized_2)\n"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  9  25   1]\n",
            " [ 16 144   1]]\n",
            "[ 5.         13.          1.41421356]\n",
            "[ 5.         13.          1.41421356]\n",
            "[[0.6        0.38461538 0.70710678]\n",
            " [0.8        0.92307692 0.70710678]]\n",
            "[[1.8973666  1.21626064 2.23606798]\n",
            " [2.52982213 2.91902553 2.23606798]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwKPA9rhgVAQ"
      },
      "source": [
        "def weight_norm(x):\n",
        "    x_norm = (np.sum(np.square(x),axis=0)**(1/2))\n",
        "    return x_norm"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka-cpwK6OHbw"
      },
      "source": [
        "class Network():\n",
        "  #ネットワークを定義する\n",
        "  #構成[入力層, 第1層, 第2層, 第3層, 第4層, 第5層]\n",
        "  #全結合\n",
        "\n",
        "  def __init__(self):\n",
        "    #重みの定義\n",
        "    self.w1 = np.random.randn(N,N)\n",
        "    self.w2 = np.random.randn(N,N)\n",
        "    self.w3 = np.random.randn(N,N)\n",
        "    self.w4 = np.random.randn(N,N)\n",
        "    self.w5 = np.random.randn(N,N)\n",
        "\n",
        "    #重みの正規化\n",
        "    self.J1 = self.w1 / (weight_norm(self.w1)) * (N**(1/2))\n",
        "    self.J2 = self.w2 / (weight_norm(self.w2)) * (N**(1/2))\n",
        "    self.J3 = self.w3 / (weight_norm(self.w3)) * (N**(1/2))\n",
        "    self.J4 = self.w4 / (weight_norm(self.w4)) * (N**(1/2))\n",
        "    self.J5 = self.w5 / (weight_norm(self.w5)) * (N**(1/2))\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    self.layer0 = x\n",
        "    self.layer1 = np.sign((np.dot(self.layer0, self.J1))+1e-7)\n",
        "    self.layer2 = np.sign((np.dot(self.layer1, self.J2))+1e-7)\n",
        "    self.layer3 = np.sign((np.dot(self.layer2, self.J3))+1e-7)\n",
        "    self.layer4 = np.sign((np.dot(self.layer3, self.J4))+1e-7)\n",
        "    self.out = np.sign((np.dot(self.layer4, self.J5))+1e-7)\n",
        "    return self.out\n",
        "    \n",
        "\n",
        "  def backward(self, t, y):\n",
        "    #誤差逆伝播\n",
        "    delta5 = -2*(t-y)\n",
        "    delta4 = np.dot(delta5,self.J5.T)\n",
        "    delta3 = np.dot(delta4,self.J4.T) \n",
        "    delta2 = np.dot(delta3,self.J3.T)\n",
        "    delta1 = np.dot(delta2,self.J2.T)\n",
        "\n",
        "    #重みの勾配\n",
        "    self.dedJ5 = np.dot(self.layer4.T, delta5) / delta5.shape[0]\n",
        "    self.dedJ4 = np.dot(self.layer3.T, delta4) / delta4.shape[0]\n",
        "    self.dedJ3 = np.dot(self.layer2.T, delta3) / delta3.shape[0]\n",
        "    self.dedJ2 = np.dot(self.layer1.T, delta2) / delta2.shape[0]\n",
        "    self.dedJ1 = np.dot(self.layer0.T, delta1) / delta1.shape[0]\n",
        "\n",
        "  def optimize_GradientDecent(self, lr):\n",
        "    #重みの更新    \n",
        "    self.J1 -= lr * self.dedJ1\n",
        "    self.J2 -= lr * self.dedJ2\n",
        "    self.J3 -= lr * self.dedJ3\n",
        "    self.J4 -= lr * self.dedJ4\n",
        "    self.J5 -= lr * self.dedJ5\n",
        "\n",
        "    #重みの正規化\n",
        "    self.J1 = self.J1 / (weight_norm(self.J1)) * (N**(1/2))\n",
        "    self.J2 = self.J2 / (weight_norm(self.J2)) * (N**(1/2))\n",
        "    self.J3 = self.J3 / (weight_norm(self.J3)) * (N**(1/2))\n",
        "    self.J4 = self.J4 / (weight_norm(self.J4)) * (N**(1/2))\n",
        "    self.J5 = self.J5 / (weight_norm(self.J5)) * (N**(1/2))\n",
        "\n"
      ],
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o10wudFlOHd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775b72c5-0332-4b08-f2a2-22153bf5c254"
      },
      "source": [
        "model = Network()\n",
        "\n",
        "# 学習率\n",
        "lr = 0.01\n",
        "# 学習エポック数\n",
        "n_epoch = 300\n",
        "\n",
        "# n_epoch繰り返す\n",
        "for n in range(n_epoch):\n",
        "    y = model.forward(S0)\n",
        "    train_loss = MSE(SL, y)\n",
        "    model.backward(SL, y)\n",
        "    model.optimize_GradientDecent(lr)\n",
        "    print('EPOCH ', n + 1, ' | TRAIN LOSS ',\n",
        "          train_loss)"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH  1  | TRAIN LOSS  16.0\n",
            "EPOCH  2  | TRAIN LOSS  12.0\n",
            "EPOCH  3  | TRAIN LOSS  14.0\n",
            "EPOCH  4  | TRAIN LOSS  20.0\n",
            "EPOCH  5  | TRAIN LOSS  18.0\n",
            "EPOCH  6  | TRAIN LOSS  24.0\n",
            "EPOCH  7  | TRAIN LOSS  20.0\n",
            "EPOCH  8  | TRAIN LOSS  16.0\n",
            "EPOCH  9  | TRAIN LOSS  14.0\n",
            "EPOCH  10  | TRAIN LOSS  24.0\n",
            "EPOCH  11  | TRAIN LOSS  16.0\n",
            "EPOCH  12  | TRAIN LOSS  12.0\n",
            "EPOCH  13  | TRAIN LOSS  18.0\n",
            "EPOCH  14  | TRAIN LOSS  16.0\n",
            "EPOCH  15  | TRAIN LOSS  20.0\n",
            "EPOCH  16  | TRAIN LOSS  22.0\n",
            "EPOCH  17  | TRAIN LOSS  20.0\n",
            "EPOCH  18  | TRAIN LOSS  14.0\n",
            "EPOCH  19  | TRAIN LOSS  18.0\n",
            "EPOCH  20  | TRAIN LOSS  18.0\n",
            "EPOCH  21  | TRAIN LOSS  22.0\n",
            "EPOCH  22  | TRAIN LOSS  24.0\n",
            "EPOCH  23  | TRAIN LOSS  20.0\n",
            "EPOCH  24  | TRAIN LOSS  8.0\n",
            "EPOCH  25  | TRAIN LOSS  14.0\n",
            "EPOCH  26  | TRAIN LOSS  22.0\n",
            "EPOCH  27  | TRAIN LOSS  14.0\n",
            "EPOCH  28  | TRAIN LOSS  10.0\n",
            "EPOCH  29  | TRAIN LOSS  12.0\n",
            "EPOCH  30  | TRAIN LOSS  16.0\n",
            "EPOCH  31  | TRAIN LOSS  16.0\n",
            "EPOCH  32  | TRAIN LOSS  14.0\n",
            "EPOCH  33  | TRAIN LOSS  12.0\n",
            "EPOCH  34  | TRAIN LOSS  16.0\n",
            "EPOCH  35  | TRAIN LOSS  10.0\n",
            "EPOCH  36  | TRAIN LOSS  8.0\n",
            "EPOCH  37  | TRAIN LOSS  8.0\n",
            "EPOCH  38  | TRAIN LOSS  12.0\n",
            "EPOCH  39  | TRAIN LOSS  20.0\n",
            "EPOCH  40  | TRAIN LOSS  6.0\n",
            "EPOCH  41  | TRAIN LOSS  10.0\n",
            "EPOCH  42  | TRAIN LOSS  6.0\n",
            "EPOCH  43  | TRAIN LOSS  10.0\n",
            "EPOCH  44  | TRAIN LOSS  6.0\n",
            "EPOCH  45  | TRAIN LOSS  8.0\n",
            "EPOCH  46  | TRAIN LOSS  10.0\n",
            "EPOCH  47  | TRAIN LOSS  12.0\n",
            "EPOCH  48  | TRAIN LOSS  18.0\n",
            "EPOCH  49  | TRAIN LOSS  16.0\n",
            "EPOCH  50  | TRAIN LOSS  8.0\n",
            "EPOCH  51  | TRAIN LOSS  28.0\n",
            "EPOCH  52  | TRAIN LOSS  14.0\n",
            "EPOCH  53  | TRAIN LOSS  26.0\n",
            "EPOCH  54  | TRAIN LOSS  16.0\n",
            "EPOCH  55  | TRAIN LOSS  18.0\n",
            "EPOCH  56  | TRAIN LOSS  20.0\n",
            "EPOCH  57  | TRAIN LOSS  14.0\n",
            "EPOCH  58  | TRAIN LOSS  16.0\n",
            "EPOCH  59  | TRAIN LOSS  12.0\n",
            "EPOCH  60  | TRAIN LOSS  16.0\n",
            "EPOCH  61  | TRAIN LOSS  12.0\n",
            "EPOCH  62  | TRAIN LOSS  6.0\n",
            "EPOCH  63  | TRAIN LOSS  8.0\n",
            "EPOCH  64  | TRAIN LOSS  16.0\n",
            "EPOCH  65  | TRAIN LOSS  4.0\n",
            "EPOCH  66  | TRAIN LOSS  2.0\n",
            "EPOCH  67  | TRAIN LOSS  2.0\n",
            "EPOCH  68  | TRAIN LOSS  8.0\n",
            "EPOCH  69  | TRAIN LOSS  6.0\n",
            "EPOCH  70  | TRAIN LOSS  8.0\n",
            "EPOCH  71  | TRAIN LOSS  12.0\n",
            "EPOCH  72  | TRAIN LOSS  20.0\n",
            "EPOCH  73  | TRAIN LOSS  12.0\n",
            "EPOCH  74  | TRAIN LOSS  16.0\n",
            "EPOCH  75  | TRAIN LOSS  12.0\n",
            "EPOCH  76  | TRAIN LOSS  18.0\n",
            "EPOCH  77  | TRAIN LOSS  12.0\n",
            "EPOCH  78  | TRAIN LOSS  18.0\n",
            "EPOCH  79  | TRAIN LOSS  24.0\n",
            "EPOCH  80  | TRAIN LOSS  8.0\n",
            "EPOCH  81  | TRAIN LOSS  8.0\n",
            "EPOCH  82  | TRAIN LOSS  24.0\n",
            "EPOCH  83  | TRAIN LOSS  22.0\n",
            "EPOCH  84  | TRAIN LOSS  12.0\n",
            "EPOCH  85  | TRAIN LOSS  12.0\n",
            "EPOCH  86  | TRAIN LOSS  14.0\n",
            "EPOCH  87  | TRAIN LOSS  10.0\n",
            "EPOCH  88  | TRAIN LOSS  20.0\n",
            "EPOCH  89  | TRAIN LOSS  22.0\n",
            "EPOCH  90  | TRAIN LOSS  28.0\n",
            "EPOCH  91  | TRAIN LOSS  12.0\n",
            "EPOCH  92  | TRAIN LOSS  28.0\n",
            "EPOCH  93  | TRAIN LOSS  20.0\n",
            "EPOCH  94  | TRAIN LOSS  8.0\n",
            "EPOCH  95  | TRAIN LOSS  18.0\n",
            "EPOCH  96  | TRAIN LOSS  12.0\n",
            "EPOCH  97  | TRAIN LOSS  16.0\n",
            "EPOCH  98  | TRAIN LOSS  22.0\n",
            "EPOCH  99  | TRAIN LOSS  8.0\n",
            "EPOCH  100  | TRAIN LOSS  20.0\n",
            "EPOCH  101  | TRAIN LOSS  12.0\n",
            "EPOCH  102  | TRAIN LOSS  22.0\n",
            "EPOCH  103  | TRAIN LOSS  24.0\n",
            "EPOCH  104  | TRAIN LOSS  24.0\n",
            "EPOCH  105  | TRAIN LOSS  8.0\n",
            "EPOCH  106  | TRAIN LOSS  14.0\n",
            "EPOCH  107  | TRAIN LOSS  14.0\n",
            "EPOCH  108  | TRAIN LOSS  18.0\n",
            "EPOCH  109  | TRAIN LOSS  16.0\n",
            "EPOCH  110  | TRAIN LOSS  22.0\n",
            "EPOCH  111  | TRAIN LOSS  12.0\n",
            "EPOCH  112  | TRAIN LOSS  26.0\n",
            "EPOCH  113  | TRAIN LOSS  16.0\n",
            "EPOCH  114  | TRAIN LOSS  18.0\n",
            "EPOCH  115  | TRAIN LOSS  12.0\n",
            "EPOCH  116  | TRAIN LOSS  10.0\n",
            "EPOCH  117  | TRAIN LOSS  14.0\n",
            "EPOCH  118  | TRAIN LOSS  10.0\n",
            "EPOCH  119  | TRAIN LOSS  8.0\n",
            "EPOCH  120  | TRAIN LOSS  12.0\n",
            "EPOCH  121  | TRAIN LOSS  8.0\n",
            "EPOCH  122  | TRAIN LOSS  12.0\n",
            "EPOCH  123  | TRAIN LOSS  14.0\n",
            "EPOCH  124  | TRAIN LOSS  20.0\n",
            "EPOCH  125  | TRAIN LOSS  12.0\n",
            "EPOCH  126  | TRAIN LOSS  8.0\n",
            "EPOCH  127  | TRAIN LOSS  28.0\n",
            "EPOCH  128  | TRAIN LOSS  26.0\n",
            "EPOCH  129  | TRAIN LOSS  26.0\n",
            "EPOCH  130  | TRAIN LOSS  22.0\n",
            "EPOCH  131  | TRAIN LOSS  14.0\n",
            "EPOCH  132  | TRAIN LOSS  16.0\n",
            "EPOCH  133  | TRAIN LOSS  14.0\n",
            "EPOCH  134  | TRAIN LOSS  8.0\n",
            "EPOCH  135  | TRAIN LOSS  12.0\n",
            "EPOCH  136  | TRAIN LOSS  6.0\n",
            "EPOCH  137  | TRAIN LOSS  16.0\n",
            "EPOCH  138  | TRAIN LOSS  6.0\n",
            "EPOCH  139  | TRAIN LOSS  6.0\n",
            "EPOCH  140  | TRAIN LOSS  16.0\n",
            "EPOCH  141  | TRAIN LOSS  10.0\n",
            "EPOCH  142  | TRAIN LOSS  10.0\n",
            "EPOCH  143  | TRAIN LOSS  6.0\n",
            "EPOCH  144  | TRAIN LOSS  16.0\n",
            "EPOCH  145  | TRAIN LOSS  18.0\n",
            "EPOCH  146  | TRAIN LOSS  20.0\n",
            "EPOCH  147  | TRAIN LOSS  24.0\n",
            "EPOCH  148  | TRAIN LOSS  16.0\n",
            "EPOCH  149  | TRAIN LOSS  12.0\n",
            "EPOCH  150  | TRAIN LOSS  12.0\n",
            "EPOCH  151  | TRAIN LOSS  14.0\n",
            "EPOCH  152  | TRAIN LOSS  16.0\n",
            "EPOCH  153  | TRAIN LOSS  14.0\n",
            "EPOCH  154  | TRAIN LOSS  18.0\n",
            "EPOCH  155  | TRAIN LOSS  24.0\n",
            "EPOCH  156  | TRAIN LOSS  16.0\n",
            "EPOCH  157  | TRAIN LOSS  8.0\n",
            "EPOCH  158  | TRAIN LOSS  18.0\n",
            "EPOCH  159  | TRAIN LOSS  24.0\n",
            "EPOCH  160  | TRAIN LOSS  12.0\n",
            "EPOCH  161  | TRAIN LOSS  12.0\n",
            "EPOCH  162  | TRAIN LOSS  20.0\n",
            "EPOCH  163  | TRAIN LOSS  32.0\n",
            "EPOCH  164  | TRAIN LOSS  26.0\n",
            "EPOCH  165  | TRAIN LOSS  28.0\n",
            "EPOCH  166  | TRAIN LOSS  8.0\n",
            "EPOCH  167  | TRAIN LOSS  20.0\n",
            "EPOCH  168  | TRAIN LOSS  20.0\n",
            "EPOCH  169  | TRAIN LOSS  12.0\n",
            "EPOCH  170  | TRAIN LOSS  10.0\n",
            "EPOCH  171  | TRAIN LOSS  24.0\n",
            "EPOCH  172  | TRAIN LOSS  10.0\n",
            "EPOCH  173  | TRAIN LOSS  14.0\n",
            "EPOCH  174  | TRAIN LOSS  22.0\n",
            "EPOCH  175  | TRAIN LOSS  14.0\n",
            "EPOCH  176  | TRAIN LOSS  6.0\n",
            "EPOCH  177  | TRAIN LOSS  10.0\n",
            "EPOCH  178  | TRAIN LOSS  20.0\n",
            "EPOCH  179  | TRAIN LOSS  18.0\n",
            "EPOCH  180  | TRAIN LOSS  16.0\n",
            "EPOCH  181  | TRAIN LOSS  8.0\n",
            "EPOCH  182  | TRAIN LOSS  2.0\n",
            "EPOCH  183  | TRAIN LOSS  2.0\n",
            "EPOCH  184  | TRAIN LOSS  8.0\n",
            "EPOCH  185  | TRAIN LOSS  16.0\n",
            "EPOCH  186  | TRAIN LOSS  14.0\n",
            "EPOCH  187  | TRAIN LOSS  6.0\n",
            "EPOCH  188  | TRAIN LOSS  6.0\n",
            "EPOCH  189  | TRAIN LOSS  12.0\n",
            "EPOCH  190  | TRAIN LOSS  12.0\n",
            "EPOCH  191  | TRAIN LOSS  14.0\n",
            "EPOCH  192  | TRAIN LOSS  14.0\n",
            "EPOCH  193  | TRAIN LOSS  12.0\n",
            "EPOCH  194  | TRAIN LOSS  20.0\n",
            "EPOCH  195  | TRAIN LOSS  26.0\n",
            "EPOCH  196  | TRAIN LOSS  22.0\n",
            "EPOCH  197  | TRAIN LOSS  12.0\n",
            "EPOCH  198  | TRAIN LOSS  12.0\n",
            "EPOCH  199  | TRAIN LOSS  12.0\n",
            "EPOCH  200  | TRAIN LOSS  8.0\n",
            "EPOCH  201  | TRAIN LOSS  12.0\n",
            "EPOCH  202  | TRAIN LOSS  18.0\n",
            "EPOCH  203  | TRAIN LOSS  16.0\n",
            "EPOCH  204  | TRAIN LOSS  20.0\n",
            "EPOCH  205  | TRAIN LOSS  24.0\n",
            "EPOCH  206  | TRAIN LOSS  8.0\n",
            "EPOCH  207  | TRAIN LOSS  24.0\n",
            "EPOCH  208  | TRAIN LOSS  20.0\n",
            "EPOCH  209  | TRAIN LOSS  14.0\n",
            "EPOCH  210  | TRAIN LOSS  12.0\n",
            "EPOCH  211  | TRAIN LOSS  10.0\n",
            "EPOCH  212  | TRAIN LOSS  12.0\n",
            "EPOCH  213  | TRAIN LOSS  14.0\n",
            "EPOCH  214  | TRAIN LOSS  10.0\n",
            "EPOCH  215  | TRAIN LOSS  10.0\n",
            "EPOCH  216  | TRAIN LOSS  14.0\n",
            "EPOCH  217  | TRAIN LOSS  18.0\n",
            "EPOCH  218  | TRAIN LOSS  22.0\n",
            "EPOCH  219  | TRAIN LOSS  12.0\n",
            "EPOCH  220  | TRAIN LOSS  8.0\n",
            "EPOCH  221  | TRAIN LOSS  16.0\n",
            "EPOCH  222  | TRAIN LOSS  12.0\n",
            "EPOCH  223  | TRAIN LOSS  6.0\n",
            "EPOCH  224  | TRAIN LOSS  20.0\n",
            "EPOCH  225  | TRAIN LOSS  10.0\n",
            "EPOCH  226  | TRAIN LOSS  12.0\n",
            "EPOCH  227  | TRAIN LOSS  2.0\n",
            "EPOCH  228  | TRAIN LOSS  14.0\n",
            "EPOCH  229  | TRAIN LOSS  10.0\n",
            "EPOCH  230  | TRAIN LOSS  22.0\n",
            "EPOCH  231  | TRAIN LOSS  22.0\n",
            "EPOCH  232  | TRAIN LOSS  12.0\n",
            "EPOCH  233  | TRAIN LOSS  10.0\n",
            "EPOCH  234  | TRAIN LOSS  14.0\n",
            "EPOCH  235  | TRAIN LOSS  16.0\n",
            "EPOCH  236  | TRAIN LOSS  12.0\n",
            "EPOCH  237  | TRAIN LOSS  14.0\n",
            "EPOCH  238  | TRAIN LOSS  6.0\n",
            "EPOCH  239  | TRAIN LOSS  10.0\n",
            "EPOCH  240  | TRAIN LOSS  8.0\n",
            "EPOCH  241  | TRAIN LOSS  8.0\n",
            "EPOCH  242  | TRAIN LOSS  6.0\n",
            "EPOCH  243  | TRAIN LOSS  10.0\n",
            "EPOCH  244  | TRAIN LOSS  12.0\n",
            "EPOCH  245  | TRAIN LOSS  20.0\n",
            "EPOCH  246  | TRAIN LOSS  16.0\n",
            "EPOCH  247  | TRAIN LOSS  8.0\n",
            "EPOCH  248  | TRAIN LOSS  12.0\n",
            "EPOCH  249  | TRAIN LOSS  8.0\n",
            "EPOCH  250  | TRAIN LOSS  32.0\n",
            "EPOCH  251  | TRAIN LOSS  28.0\n",
            "EPOCH  252  | TRAIN LOSS  16.0\n",
            "EPOCH  253  | TRAIN LOSS  16.0\n",
            "EPOCH  254  | TRAIN LOSS  16.0\n",
            "EPOCH  255  | TRAIN LOSS  8.0\n",
            "EPOCH  256  | TRAIN LOSS  16.0\n",
            "EPOCH  257  | TRAIN LOSS  18.0\n",
            "EPOCH  258  | TRAIN LOSS  28.0\n",
            "EPOCH  259  | TRAIN LOSS  28.0\n",
            "EPOCH  260  | TRAIN LOSS  20.0\n",
            "EPOCH  261  | TRAIN LOSS  22.0\n",
            "EPOCH  262  | TRAIN LOSS  16.0\n",
            "EPOCH  263  | TRAIN LOSS  12.0\n",
            "EPOCH  264  | TRAIN LOSS  18.0\n",
            "EPOCH  265  | TRAIN LOSS  16.0\n",
            "EPOCH  266  | TRAIN LOSS  12.0\n",
            "EPOCH  267  | TRAIN LOSS  24.0\n",
            "EPOCH  268  | TRAIN LOSS  12.0\n",
            "EPOCH  269  | TRAIN LOSS  18.0\n",
            "EPOCH  270  | TRAIN LOSS  12.0\n",
            "EPOCH  271  | TRAIN LOSS  20.0\n",
            "EPOCH  272  | TRAIN LOSS  16.0\n",
            "EPOCH  273  | TRAIN LOSS  28.0\n",
            "EPOCH  274  | TRAIN LOSS  22.0\n",
            "EPOCH  275  | TRAIN LOSS  12.0\n",
            "EPOCH  276  | TRAIN LOSS  20.0\n",
            "EPOCH  277  | TRAIN LOSS  16.0\n",
            "EPOCH  278  | TRAIN LOSS  14.0\n",
            "EPOCH  279  | TRAIN LOSS  16.0\n",
            "EPOCH  280  | TRAIN LOSS  14.0\n",
            "EPOCH  281  | TRAIN LOSS  12.0\n",
            "EPOCH  282  | TRAIN LOSS  18.0\n",
            "EPOCH  283  | TRAIN LOSS  4.0\n",
            "EPOCH  284  | TRAIN LOSS  16.0\n",
            "EPOCH  285  | TRAIN LOSS  14.0\n",
            "EPOCH  286  | TRAIN LOSS  20.0\n",
            "EPOCH  287  | TRAIN LOSS  12.0\n",
            "EPOCH  288  | TRAIN LOSS  22.0\n",
            "EPOCH  289  | TRAIN LOSS  20.0\n",
            "EPOCH  290  | TRAIN LOSS  16.0\n",
            "EPOCH  291  | TRAIN LOSS  24.0\n",
            "EPOCH  292  | TRAIN LOSS  24.0\n",
            "EPOCH  293  | TRAIN LOSS  20.0\n",
            "EPOCH  294  | TRAIN LOSS  12.0\n",
            "EPOCH  295  | TRAIN LOSS  24.0\n",
            "EPOCH  296  | TRAIN LOSS  16.0\n",
            "EPOCH  297  | TRAIN LOSS  16.0\n",
            "EPOCH  298  | TRAIN LOSS  20.0\n",
            "EPOCH  299  | TRAIN LOSS  8.0\n",
            "EPOCH  300  | TRAIN LOSS  16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBM9kt6qOHm2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRHcK1edOHrJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCQ57LHkOHtT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}